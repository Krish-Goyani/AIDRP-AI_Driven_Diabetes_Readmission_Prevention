{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\DataScience\\\\Projects\\\\folder\\\\AIDRP-AI_Driven_Diabetes_Readmission_Prevention'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.AIDRP.constants import *\n",
    "from src.AIDRP.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.AIDRP.logging import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "    def data_transformation(self):\n",
    "        ## Drop the value which is not relevant for the model\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        data.drop(index=[30506, 75551, 82573],inplace=True)\n",
    "        data.drop_duplicates(subset='patient_nbr',keep='first',inplace=True)\n",
    "        data.drop(columns=['weight','citoglipton','examide','payer_code','medical_specialty','encounter_id','patient_nbr','repaglinide',\n",
    "                            'nateglinide','chlorpropamide','acetohexamide','tolbutamide', \n",
    "                            'acarbose','miglitol','troglitazone', 'tolazamide','examide',\n",
    "                            'glyburide-metformin','glipizide-metformin',\n",
    "                            'glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone'],inplace=True)\n",
    "         \n",
    "    #def diag_cluster(self,col,data):\n",
    "\n",
    "         \n",
    "         \n",
    "                            # all three diag features have more than 700 unqie we are grouping them based on ICD-9 codes\n",
    "\n",
    "        index=[]\n",
    "        index=list(data[data['diag_1']=='?'].index)\n",
    "        index.extend(data[data['diag_2']=='?'].index)\n",
    "        index.extend(data[data['diag_3']=='?'].index)\n",
    "        data.drop(index=index,inplace=True)\n",
    "\n",
    "        # all three diag features have more than 700 unqie we are grouping them based on ICD-9 codes\n",
    "        diag_cols=['diag_1','diag_2','diag_3']\n",
    "        for i in diag_cols:\n",
    "            diag_list=[]\n",
    "            for x in data[i]:\n",
    "                                # If the value in the 'col' column contains 'V' or 'E', it is assigned a cluster value of 18.\n",
    "                                if 'V' in x or 'E' in x: \n",
    "                                    diag_list.append(18)\n",
    "                                    continue\n",
    "                                # The following conditions assign cluster values based on specific ranges of float values.\n",
    "                                elif 1 <= float(x) <= 139:\n",
    "                                    diag_list.append(1)\n",
    "                                elif 140 <= float(x) <= 239:\n",
    "                                    diag_list.append(2)\n",
    "                                elif 240 <= float(x) <= 279:\n",
    "                                    diag_list.append(3)\n",
    "                                elif 280 <= float(x) <= 289:\n",
    "                                    diag_list.append(4)\n",
    "                                elif 290 <= float(x) <= 319:\n",
    "                                    diag_list.append(5)\n",
    "                                elif 320 <= float(x) <= 389:\n",
    "                                    diag_list.append(6)\n",
    "                                elif 390 <= float(x) <= 459:\n",
    "                                    diag_list.append(7)\n",
    "                                elif 460 <= float(x) <= 519:\n",
    "                                    diag_list.append(8)\n",
    "                                elif 520 <= float(x) <= 579:\n",
    "                                    diag_list.append(9)\n",
    "                                elif 580 <= float(x) <= 629:\n",
    "                                    diag_list.append(10)\n",
    "                                elif 630 <= float(x) <= 679:\n",
    "                                    diag_list.append(11)\n",
    "                                elif 680 <= float(x) <= 709:\n",
    "                                    diag_list.append(12)\n",
    "                                elif 710 <= float(x) <= 739:\n",
    "                                    diag_list.append(13)\n",
    "                                elif 740 <= float(x) <= 759:\n",
    "                                    diag_list.append(14)\n",
    "                                elif 760 <= float(x) <= 779:\n",
    "                                    diag_list.append(15)\n",
    "                                elif 780 <= float(x) <= 799:\n",
    "                                    diag_list.append(16)\n",
    "                                elif 800 <= float(x) <= 999:\n",
    "                                    diag_list.append(17)\n",
    "\n",
    "\n",
    "            data[i]=diag_list\n",
    "\n",
    "\n",
    "        #feature engineering\n",
    "        # replace any occurrences of '?' in the 'race' column with 'Other'.\n",
    "        data['race'] = data['race'].apply(lambda x: 'Other' if x == '?' else x)\n",
    "        \n",
    "\n",
    "\n",
    "        data['admission_type_id']=data['admission_type_id'].apply(lambda x : 5 if x in (6,8) else x)\n",
    "        data['admission_type_id']=data['admission_type_id'].apply(lambda x : 1 if x == 4 else 2 if x==7 else x )\n",
    "\n",
    "\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 1 if x in (6,8) else x)\n",
    "        #Uncategorized/Unknown: 18, 25, 26, 12\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 18 if x in (25,26,12) else x)\n",
    "        #Expired:11, 19, 20, 21\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 11 if x in (19,20,21) else x)\n",
    "        #Hospice:13, 14\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 13 if x ==14 else x)\n",
    "        # Discharged/Transferred to Hospital: 2, 9, 10, 23, 27, 28, 29\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 2 if x in ( 9, 10, 23, 27, 28, 29) else x)\n",
    "        #Discharged/Transferred to Care Facility: 3, 4, 5, 15, 24\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 3 if x in ( 4, 5, 15, 24) else x)\n",
    "        #Discharged to Outpatient Services:16, 17\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 16 if x ==17 else x)\n",
    "\n",
    "\n",
    "        # Unknown/Invalid: 9, 15, 17, 20, 21\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 9 if x in (15, 17, 20, 21) else x)\n",
    "        # Physician/Clinic Referral:1, 2, 3\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 1 if x in (2,3) else x)\n",
    "        #Transfer from Hospital: 4, 10, 22\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 4 if x in (10,22) else x)\n",
    "        #Transfer from Facility:5, 6, 18, 19, 25, 26\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 5 if x in (6, 18, 19, 25, 26) else x)\n",
    "        #Delivery:11, 12, 13, 14\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 11 if x in (12, 13, 14) else x)\n",
    "\n",
    "        data['change']=data['change'].apply(lambda x: 'Yes' if x=='Ch' else x)\n",
    "        data['change']=data['change'].apply(lambda x : 0 if x=='No' else 1)\n",
    "\n",
    "        data['gender']=data['gender'].apply(lambda x: 0 if x=='Female' else 1)\n",
    "\n",
    "     \n",
    "        data['diabetesMed']=data['diabetesMed'].apply(lambda x : 0 if x=='No' else 1)\n",
    "        data['readmitted']=data['readmitted'].apply(lambda x : 1 if x=='<30' else 0)\n",
    "\n",
    "        medicines =['insulin', 'metformin', 'glipizide' ,'glyburide' ,'rosiglitazone', 'pioglitazone' ,'glimepiride']\n",
    "        for med in medicines:\n",
    "            data[med]=data[med].apply(lambda x: 0 if x=='Down' else 1 if x=='No' else 2 if x=='Steady' else 3)\n",
    "\n",
    "\n",
    "        mgs=data['max_glu_serum'].dropna().values\n",
    "        a1=data['A1Cresult'].dropna().values\n",
    "        data['max_glu_serum']=data['max_glu_serum'].apply(lambda x: random.choice(mgs) if pd.isna(x) else x)\n",
    "        data['A1Cresult']=data['A1Cresult'].apply(lambda x: random.choice(a1) if pd.isna(x) else x)\n",
    "\n",
    "        mapping_dict = {\"Norm\": 1, \">7\": 2, \">8\": 2.5}\n",
    "\n",
    "        # Apply the mapping to the 'max_glu_serum' column\n",
    "        data['A1Cresult'] = data['A1Cresult'].map(mapping_dict)\n",
    "        \n",
    "\n",
    "        mapping_dict = {\"Norm\": 1, \">200\": 1.5, \">300\": 2.5}\n",
    "\n",
    "        # Apply the mapping to the 'max_glu_serum' column\n",
    "        data['max_glu_serum'] = data['max_glu_serum'].map(mapping_dict)\n",
    "\n",
    "        \n",
    "        #replace age range with 1 to 10\n",
    "        age_ranges = ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)','[60-70)', '[70-80)', '[80-90)', '[90-100)']\n",
    "        values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        \n",
    "        # The function iterates through the age_ranges and replaces each occurrence in the 'feature' with the corresponding numerical value.\n",
    "        for i, age_range in enumerate(age_ranges):\n",
    "            data['age'] = data['age'].replace(age_range, values[i])\n",
    "\n",
    "        \n",
    "\n",
    "        encoder=LabelEncoder()\n",
    "        data['race']=encoder.fit_transform(data['race'])  \n",
    "\n",
    "       # Performing a merge (cross join) on the common key\n",
    "      \n",
    "        X = data[['num_lab_procedures', 'num_medications', 'diag_3', 'diag_1', 'age',\n",
    "            'diag_2', 'time_in_hospital', 'number_diagnoses', 'num_procedures',\n",
    "            'admission_source_id', 'race', 'admission_type_id',\n",
    "            'discharge_disposition_id', 'insulin', 'diabetesMed', 'change',\n",
    "            'metformin', 'glipizide', 'number_outpatient', 'glyburide', 'pioglitazone', 'number_inpatient',\n",
    "            'number_emergency','max_glu_serum', 'A1Cresult']]\n",
    "        y = data['readmitted']\n",
    "\n",
    "        sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "       # Convert X_res to DataFrame if it's not already\n",
    "        X_res['readmitted']=y_res\n",
    "        data=X_res\n",
    "\n",
    "        # we have found that there are many entries of some users in dataset it will make our ML algorithm biased so removing them.\n",
    "        train, test = train_test_split(data)\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "        logger.info(\"Splited data into training and test sets\")\n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "\n",
    "        print(train.shape)\n",
    "        print(test.shape)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-12 20:44:13,728 : INFO : common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-02-12 20:44:13,734 : INFO : common : yaml file: params.yaml loaded successfully]\n",
      "[2024-02-12 20:44:13,743 : INFO : common : yaml file: schema.yaml loaded successfully]\n",
      "[2024-02-12 20:44:13,749 : INFO : common : created directory at: artifacts]\n",
      "[2024-02-12 20:44:13,753 : INFO : common : created directory at: artifacts/data_transformation]\n",
      "[2024-02-12 20:44:16,717 : INFO : 1922080630 : Splited data into training and test sets]\n",
      "[2024-02-12 20:44:16,719 : INFO : 1922080630 : (96004, 26)]\n",
      "[2024-02-12 20:44:16,719 : INFO : 1922080630 : (32002, 26)]\n",
      "(96004, 26)\n",
      "(32002, 26)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
