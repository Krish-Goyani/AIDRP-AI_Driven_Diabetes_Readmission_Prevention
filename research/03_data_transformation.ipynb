{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('AIDRP-AI_Driven_Diabetes_Readmission_Prevention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\DataScience\\\\Projects\\\\folder\\\\AIDRP-AI_Driven_Diabetes_Readmission_Prevention'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\DataScience\\\\Projects\\\\folder'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAIDRP\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAIDRP\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_yaml,create_directories\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConfigurationManager\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m      7\u001b[0m         config_filepath \u001b[38;5;241m=\u001b[39m CONFIG_FILE_PATH,\n\u001b[0;32m      8\u001b[0m         params_filepath \u001b[38;5;241m=\u001b[39m PARAMS_FILE_PATH,\n\u001b[0;32m      9\u001b[0m         schema_filepath \u001b[38;5;241m=\u001b[39m SCHEMA_FILE_PATH):\n",
      "File \u001b[1;32mc:\\DataScience\\Projects\\folder\\AIDRP-AI_Driven_Diabetes_Readmission_Prevention\\src\\AIDRP\\utils\\common.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BoxValueError\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mAIDRP\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "from src.AIDRP.constants import *\n",
    "from src.AIDRP.utils.common import read_yaml,create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_transformation_config(self)->DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config=DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-box\n",
      "  Obtaining dependency information for python-box from https://files.pythonhosted.org/packages/b8/0e/2aea4a9180e3cf58efe4119ce8c9f75ef97f2666bd1fe2b1b5cd8e36170c/python_box-7.1.1-cp38-cp38-win_amd64.whl.metadata\n",
      "  Downloading python_box-7.1.1-cp38-cp38-win_amd64.whl.metadata (8.0 kB)\n",
      "Downloading python_box-7.1.1-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 960.0 kB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.2 MB 907.3 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.4/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.5/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.7/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.9/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.9/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.9/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.1/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.1/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.1/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 976.1 kB/s eta 0:00:00\n",
      "Installing collected packages: python-box\n",
      "Successfully installed python-box-7.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.AIDRP.logging import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "        \n",
    "    \n",
    "    def drop_columns(self,data):\n",
    "\n",
    "        ## Drop the value which is not relevant for the model\n",
    "\n",
    "        data.drop(index=[30506, 75551, 82573],inplace=True)\n",
    "        data.drop_duplicates(subset='patient_nbr',keep='first',inplace=True)\n",
    "        data.drop(columns=['weight','citoglipton','examide','payer_code','medical_specialty','encounter_id','patient_nbr','repaglinide',\n",
    "                            'nateglinide','chlorpropamide','acetohexamide','tolbutamide', \n",
    "                            'acarbose','miglitol','troglitazone', 'tolazamide','examide',\n",
    "                            'glyburide-metformin','glipizide-metformin',\n",
    "                            'glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone'],inplace=True)\n",
    "         \n",
    "    def diag_cluster(self,col,data):\n",
    "\n",
    "                            # all three diag features have more than 700 unqie we are grouping them based on ICD-9 codes\n",
    "                            diag_list=[]\n",
    "\n",
    "                            for x in data[col]:\n",
    "                                # If the value in the 'col' column contains 'V' or 'E', it is assigned a cluster value of 18.\n",
    "                                if 'V' in x or 'E' in x: \n",
    "                                    diag_list.append(18)\n",
    "                                    continue\n",
    "                                # The following conditions assign cluster values based on specific ranges of float values.\n",
    "                                elif 1 <= float(x) <= 139:\n",
    "                                    diag_list.append(1)\n",
    "                                elif 140 <= float(x) <= 239:\n",
    "                                    diag_list.append(2)\n",
    "                                elif 240 <= float(x) <= 279:\n",
    "                                    diag_list.append(3)\n",
    "                                elif 280 <= float(x) <= 289:\n",
    "                                    diag_list.append(4)\n",
    "                                elif 290 <= float(x) <= 319:\n",
    "                                    diag_list.append(5)\n",
    "                                elif 320 <= float(x) <= 389:\n",
    "                                    diag_list.append(6)\n",
    "                                elif 390 <= float(x) <= 459:\n",
    "                                    diag_list.append(7)\n",
    "                                elif 460 <= float(x) <= 519:\n",
    "                                    diag_list.append(8)\n",
    "                                elif 520 <= float(x) <= 579:\n",
    "                                    diag_list.append(9)\n",
    "                                elif 580 <= float(x) <= 629:\n",
    "                                    diag_list.append(10)\n",
    "                                elif 630 <= float(x) <= 679:\n",
    "                                    diag_list.append(11)\n",
    "                                elif 680 <= float(x) <= 709:\n",
    "                                    diag_list.append(12)\n",
    "                                elif 710 <= float(x) <= 739:\n",
    "                                    diag_list.append(13)\n",
    "                                elif 740 <= float(x) <= 759:\n",
    "                                    diag_list.append(14)\n",
    "                                elif 760 <= float(x) <= 779:\n",
    "                                    diag_list.append(15)\n",
    "                                elif 780 <= float(x) <= 799:\n",
    "                                    diag_list.append(16)\n",
    "                                elif 800 <= float(x) <= 999:\n",
    "                                    diag_list.append(17)\n",
    "\n",
    "\n",
    "                            return diag_list\n",
    "    \n",
    "    def feature_enginnerings(self,data):\n",
    "\n",
    "\n",
    "        #feature engineering\n",
    "        # replace any occurrences of '?' in the 'race' column with 'Other'.\n",
    "        data['race'] = data['race'].apply(lambda x: 'Other' if x == '?' else x)\n",
    "\n",
    "        index=[]\n",
    "        index=list(data[data['diag_1']=='?'].index)\n",
    "        index.extend(data[data['diag_2']=='?'].index)\n",
    "        index.extend(data[data['diag_3']=='?'].index)\n",
    "        data.drop(index=index,inplace=True)\n",
    "\n",
    "\n",
    "        data['admission_type_id']=data['admission_type_id'].apply(lambda x : 5 if x in (6,8) else x)\n",
    "        data['admission_type_id']=data['admission_type_id'].apply(lambda x : 1 if x == 4 else 2 if x==7 else x )\n",
    "\n",
    "\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 1 if x in (6,8) else x)\n",
    "        #Uncategorized/Unknown: 18, 25, 26, 12\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 18 if x in (25,26,12) else x)\n",
    "        #Expired:11, 19, 20, 21\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 11 if x in (19,20,21) else x)\n",
    "        #Hospice:13, 14\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 13 if x ==14 else x)\n",
    "        # Discharged/Transferred to Hospital: 2, 9, 10, 23, 27, 28, 29\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 2 if x in ( 9, 10, 23, 27, 28, 29) else x)\n",
    "        #Discharged/Transferred to Care Facility: 3, 4, 5, 15, 24\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 3 if x in ( 4, 5, 15, 24) else x)\n",
    "        #Discharged to Outpatient Services:16, 17\n",
    "        data['discharge_disposition_id']=data['discharge_disposition_id'].apply(lambda x : 16 if x ==17 else x)\n",
    "\n",
    "\n",
    "        # Unknown/Invalid: 9, 15, 17, 20, 21\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 9 if x in (15, 17, 20, 21) else x)\n",
    "        # Physician/Clinic Referral:1, 2, 3\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 1 if x in (2,3) else x)\n",
    "        #Transfer from Hospital: 4, 10, 22\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 4 if x in (10,22) else x)\n",
    "        #Transfer from Facility:5, 6, 18, 19, 25, 26\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 5 if x in (6, 18, 19, 25, 26) else x)\n",
    "        #Delivery:11, 12, 13, 14\n",
    "        data['admission_source_id']= data['admission_source_id'].apply(lambda x : 11 if x in (12, 13, 14) else x)\n",
    "\n",
    "        data['change']=data['change'].apply(lambda x: 'Yes' if x=='Ch' else x)\n",
    "        data['change']=data['change'].apply(lambda x : 0 if x=='No' else 1)\n",
    "\n",
    "        data['gender']=data['gender'].apply(lambda x: 0 if x=='Female' else 1)\n",
    "\n",
    "     \n",
    "        data['diabetesMed']=data['diabetesMed'].apply(lambda x : 0 if x=='No' else 1)\n",
    "        data['readmitted']=data['readmitted'].apply(lambda x : 1 if x=='<30' else 0)\n",
    "\n",
    "        medicines =['insulin', 'metformin', 'glipizide' ,'glyburide' ,'rosiglitazone', 'pioglitazone' ,'glimepiride']\n",
    "        for med in medicines:\n",
    "            data[med]=data[med].apply(lambda x: 0 if x=='Down' else 1 if x=='No' else 2 if x=='Steady' else 3)\n",
    "\n",
    "\n",
    "        mgs=data['max_glu_serum'].dropna().values\n",
    "        a1=data['A1Cresult'].dropna().values\n",
    "        data['max_glu_serum']=data['max_glu_serum'].apply(lambda x: random.choice(mgs) if pd.isna(x) else x)\n",
    "        data['A1Cresult']=data['A1Cresult'].apply(lambda x: random.choice(a1) if pd.isna(x) else x)\n",
    "\n",
    "        mapping_dict = {\"Norm\": 1, \">7\": 2, \">8\": 2.5}\n",
    "\n",
    "        # Apply the mapping to the 'max_glu_serum' column\n",
    "        data['A1Cresult'] = data['A1Cresult'].map(mapping_dict)\n",
    "        \n",
    "\n",
    "        mapping_dict = {\"Norm\": 1, \">200\": 1.5, \">300\": 2.5}\n",
    "\n",
    "        # Apply the mapping to the 'max_glu_serum' column\n",
    "        data['max_glu_serum'] = data['max_glu_serum'].map(mapping_dict)\n",
    "\n",
    "        data['diag_1']=self.diag_cluster('diag_1',data)\n",
    "        data['diag_2']=self.diag_cluster('diag_2',data)\n",
    "        data['diag_3']=self.diag_cluster('diag_3',data)\n",
    "        \n",
    "        #replace age range with 1 to 10\n",
    "        age_ranges = ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)','[60-70)', '[70-80)', '[80-90)', '[90-100)']\n",
    "        values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        \n",
    "        # The function iterates through the age_ranges and replaces each occurrence in the 'feature' with the corresponding numerical value.\n",
    "        for i, age_range in enumerate(age_ranges):\n",
    "            data['age'] = data['age'].replace(age_range, values[i])\n",
    "\n",
    "        \n",
    "\n",
    "        encoder=LabelEncoder()\n",
    "        data['race']=encoder.fit_transform(data['race'])  \n",
    "\n",
    "    def preprocessing(self):\n",
    "        data= pd.read_csv(self.config.data_path)\n",
    "       \n",
    "\n",
    "        self.drop_columns(data)\n",
    "\n",
    "        self.feature_enginnerings(data)\n",
    "\n",
    "       # Performing a merge (cross join) on the common key\n",
    "      \n",
    "        X = data[['num_lab_procedures', 'num_medications', 'diag_3', 'diag_1', 'age',\n",
    "            'diag_2', 'time_in_hospital', 'number_diagnoses', 'num_procedures',\n",
    "            'admission_source_id', 'race', 'admission_type_id',\n",
    "            'discharge_disposition_id', 'insulin', 'diabetesMed', 'change',\n",
    "            'metformin', 'glipizide', 'number_outpatient', 'glyburide', 'pioglitazone', 'number_inpatient',\n",
    "            'number_emergency','max_glu_serum', 'A1Cresult']]\n",
    "        y = data['readmitted']\n",
    "\n",
    "        sm = SMOTE(sampling_strategy='minority', random_state=42, n_jobs=-1)\n",
    "\n",
    "      \n",
    "                \n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "       # Convert X_res to DataFrame if it's not already\n",
    "        X_res['readmitted']=y_res\n",
    "        data=X_res\n",
    "\n",
    "        # we have found that there are many entries of some users in dataset it will make our ML algorithm biased so removing them.\n",
    "        train,test = train_test_split(data)\n",
    "        # train.to_csv(self.config.root_dir,\"train.csv\",index=False)\n",
    "        # test.to_csv(self.config.root_dir,\"test.csv\",index=False)\n",
    "    \n",
    "\n",
    "      # Parent Directory path (use raw string to avoid escape characters)\n",
    "        '''parent_dir = r\"D:\\AIDRP_AI_Driven_Diabetes_Readmission_Prevention\\artifacts\"\n",
    "\n",
    "        # Create the directory for data transformation if it doesn't exist\n",
    "        directory_path = os.path.join(parent_dir, 'data_transformation')\n",
    "        os.makedirs(directory_path, exist_ok=True)'''\n",
    "\n",
    "        # Save train and test data as CSV files inside the directory\n",
    "        train.to_csv(self.config.root_dir, 'train.csv', index=False)\n",
    "        test.to_csv(self.config.root_dir, 'test.csv', index=False)\n",
    "\n",
    "        logger.info(\"Split data into training and test sets\")\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "        logger.info(\"Splited data into training and test sets\")\n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "\n",
    "        print(train.shape)\n",
    "        print(test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-11 20:29:42,849 : INFO : common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-02-11 20:29:42,869 : INFO : common : yaml file: params.yaml loaded successfully]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-11 20:29:42,912 : INFO : common : yaml file: schema.yaml loaded successfully]\n",
      "[2024-02-11 20:29:42,920 : INFO : common : created directory at: artifacts]\n",
      "[2024-02-11 20:29:42,921 : INFO : common : created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_17636\\3628481067.py:164: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['age'] = data['age'].replace(age_range, values[i])\n",
      "c:\\Python312\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:363: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-11 20:29:46,851 : INFO : 3628481067 : Split data into training and test sets]\n",
      "[2024-02-11 20:29:46,851 : INFO : 3628481067 : Splited data into training and test sets]\n",
      "[2024-02-11 20:29:46,851 : INFO : 3628481067 : (96004, 26)]\n",
      "[2024-02-11 20:29:46,851 : INFO : 3628481067 : (32002, 26)]\n",
      "(96004, 26)\n",
      "(32002, 26)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.preprocessing()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
